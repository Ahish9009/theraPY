<!DOCTYPE html>
<html>
<head>
	<title>theraPY</title>
	<link rel="stylesheet" type="text/css" href="style.css">
	<link href="https://fonts.googleapis.com/css?family=Comfortaa" rel="stylesheet">
</head>
<body>
<div id="nav1">
	<h1><a href="index.html">theraPY</a></h1>
	<ul>
		<li><a href="index.html">Home</a></li>
		<li><a href="service.html">Service</a></li>
		<li><a href="contact.html">Contact</a></li>
		<li id="active"><a href="about.html">About</a></li>
	</ul>
</div>
<div id="abstract">
	<div id="child">
		<h1>Abstract</h1>
		<br>
		<p>With tracking the eyes , pupil and iris using corneal reflection, the area of contours is calculated from the threshold image of the eye and the changes in the area's stored. Apart from the contours the other parameters are blinking rate and dilation of the pupils from their mean. A custom dataset is generated considering these parameters and also the voice input from the user. The ultimate goal is to generate a suitable music playlist for the patient on the basis of his/her involuntary responeses and speed up their recovery! For Music generation the custom dataset is combined with the set of music playlist to which the eye respones are recorded accordingly. At the real time live data from the camera is taken and is given as a input to the trained model after every round of 50 iterations . Voila! the predicted output plays a song or changes the mood!</p>
	</div>
</div>
<div id="people">
	<div id="devs">
		<h1>Developers</h1>
		<br>
		<ul>
			<p>Pulkit Pahuja</p><br>
			<p>Nilotpal Pramanik</p><br>
			<p>Nikhil Mundra</p><br>
			<p>Ruchin Agarwal</p><br>
		</ul>
	</div>
	<div id="sups">
		<h1>Technology Used</h1>
		<br>
		<ul>
			<p>OpenCV</p><br>
			<p>Dlib</p><br>
			<p>xgBoost</p><br>
		</ul>
	</div>
</div>
<div id="about-footer">
		<p>&copy;HINT 2019-AllrightReserved</p>
</div>
</body>
</html>